# 读后汇总

慢慢也算是"抄写"完了这本书，像是上学时候完成语文老师的课后作业，感觉不错，手打下来的确比前几遍单纯的看要理解得更好些。

通过理解 Java 内存模型，算是初步了解了为什么多线程程序会出现并发的问题，针对的问题就是内存可见性保证。

接下来稍稍汇总下一些知识点，方便日后查阅。

## 学习目的

1. 了解为何多线程程序会出现内存可见性问题
2. 了解如何避免出现内存可见性问题

## 知识点总结

**基础**：

- Java 中采用的是**共享内存**的并发模型。
  - 共享内存的并发模型中，线程之间通过写 - 读内存中的公共状态来隐式进行通信。
  - 共享内存的并发模型中，同步是显式进行的。
- Java 线程之间的通信由 Java 内存模型（简称为 **JMM**）控制。
  - JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 Java 程序员提供内存可见性的保证。
  - JMM 属于语言级的内存模型
  - JMM 确保在不同的编译器和不同的处理器平台上为程序员提供一致的内存可见性保证:
    - 禁止特定类型的编译器重排序和处理器重排序
    - Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。
  - JMM 把内存屏障指令分为下列四类（前指令装载之前于后指令装载）
    - LoadLoad Barriers -> [ Load1；LoadLoad；Load2 ]
    - StoreStore Barriers -> [ Store1；StoreStore；Store2 ]
    - LoadStore Barriers -> [ Load1,；LoadStore；Store2 ]
    - StoreLoad Barriers -> [ Store1；StoreLoad；Load2 ]
- 在执行程序时，为了提高性能，编译器和处理器常常会对指令做**重排序**。重排序分为三种类型：
  - 编译器优化的重排序
  - 指令级并行的重排序
  - 内存系统的重排序。
- 从 JDK5 开始，Java 开始使用新的 **JSR-133** 内存模型
  - JSR-133 使用 happens-before 的概念来阐述操作之间的内存可见性。
  - happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。
  - 一个 happens-before 规则对应于一个或多个编译器和处理器重排序规则。
  - 与程序员密切相关的 happens-before 规则如下：
    - 程序顺序规则：一个线程中的每个操作，happens-before 于该线程中任意后续操作
    - 监视器锁规则：对一个监视器的解锁，happens-before 于随后对这个监视器的加锁
    - volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。
    - 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。

**重排序**：

- 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在**数据依赖性**。
  - 编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。
  - 这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作。
- **as-if-serial** 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。
  - 编译器，runtime和处理器都必须遵守 as-if-serial 语义。
  - as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。
- 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果。
- 在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。

**顺序一致性**：

- 如果一个多线程程序能正确同步，这个程序将是一个没有**数据竞争**的程序。
- JMM 对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有**顺序一致性**。
- **顺序一致性内存模型**是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。
- **顺序一致性内存模型**有两大特性：
  - 一个线程中的所有操作必须按照程序的顺序来执行。
  - （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。
- 未同步程序在 **JMM** 中执行时，整体上是无序的，其执行结果无法预知。

**volatile**：

- **volatile** 变量自身具有的特性：
  - 可见性。对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。
  - 原子性。对任意单个 volatile 变量的读/写具有原子性，但类似于 volatile++ 这种复合操作不具有原子性。
- volatile 写的内存语义：当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。
- volatile 读的内存语义：当读一个 volatile 变量时，JMM 会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。
- **JSR-133** 为什么要增强 volatile 的内存语义？
  - 为了提供一种比锁更轻量级的线程之间通信的机制
- 从 JSR-133 开始（即从 JDK5 开始），volatile 变量的写-读可以实现线程之间的通信。
  - volatile 写和锁的释放有相同的内存语义。
  - volatile 读与锁的获取有相同的内存语义。
- **volatile** 与**锁**的比较
  - volatile 仅仅保证对单个 volatile 变量的读/写具有原子性
  - 锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性
  - 在功能上，锁比 volatile 更强大。
  - 在可伸缩性和执行性能上，volatile 更有优势。

**锁**：

- **锁**除了让临界点互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。
- **锁**释放和锁获取的内存语义总结：
  - 线程 A 释放一个锁，实质上是线程 A 向接下来将要获取这个锁的某个线程发出了（线程 A 对共享变量所做修改的）消息。
  - 线程 B 获取一个锁，实质上是线程 B 接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。
  - 线程 A 释放锁，随后线程 B 获取这个锁，这个过程实质上是线程 A 通过主内存向线程 B 发送消息。
- 锁实现示例：ReentrantLock（JDK提供的一个可重入互斥锁）
  - ReentrantLock 的实现依赖于 Java 同步器框架 AbstractQueuedSynchronizer（本文简称之为 AQS）。
  - AQS 使用一个整型的 volatile 变量（命名为 state）来维护同步状态。
  - ReentrantLock 分为公平锁和非公平锁。
    - 公平锁在释放锁的最后写 volatile 变量 state
    - 公平锁在获取锁时首先读这个 volatile 变量 state。
    - 非公平锁的释放和公平锁完全一样。
    - 非公平锁获取时，首先会用 CAS 更新这个 volatile 变量，这个操作同时具有 volatile 读和 volatile 写的内存语义。
  - Java 的 CAS 会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键。
- 由于 Java 的 CAS 同时具有 volatile 读和 volatile 写的内存语义，因此 Java 线程之间的通信现在有了下面四种方式：
  1. A 线程写 volatile 变量，随后 B 线程读这个 volatile 变量。
  2. A 线程写 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。
  3. A 线程用 CAS 更新一个 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。
  4. A 线程用 CAS 更新一个 volatile 变量，随后 B 线程读这个 volatile 变量。
- concurrent 包源代码通用化的实现模式：
  1. 首先，声明共享变量为 volatile；
  2. 然后，使用 CAS 的原子条件更新来实现线程之间的同步；
  3. 同时，配合以 volatile 的读/写和 CAS 所具有的 volatile 读和写的内存语义来实现线程之间的通信。

**final**：

- 对于 final 域，编译器和处理器要遵守两个重排序原则：
  1. 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作不能重排序。
  2. 初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作不能重排序。
- 写 final 域的重排序规则禁止把 final 域的写重排序到构造函数之外。这个规则的实现包含下面两个方面：
  1. JMM 禁止编译器把 final 域的写重排序到构造函数之外。
  2. 编译器会在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 屏障。这个屏障禁止处理器把 final 域的写重排序到构造函数之外。
- 读 final 域的重排序规则：
  1. 在一个线程中，初次读对象引用与初次读该对象包含的 final 域，JMM 禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读 final 域操作的前面插入一个 LoadLoad 屏障。
- 对于 final 对象是**引用类型**的，写 final 域的重排序规则对编译器和处理器增加了如下约束：在构造函数内对一个 final 引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。

## 名词解释

线程通信：指线程之间以何种机制来交换信息

线程同步：指程序用于控制不同线程之间操作发生相对顺序的机制。

JMM：Java Memory Model，Java内存模型

JSR：Java Specification Requests，Java 规范提案

JSR-133：Java Memory Model and Thread Specification Revision，Java内存模型和线程规范修订版

AQS：Java 同步器框架 AbstractQueuedSynchronizer（抽象类）

CAS：Java 中的 compareAndSet 方法调用简称。例 AbstractQueuedSynchronizer:compareAndSetState(int expect, int update)。

## 想法池

对于学习目的上的两个问题可以在总结后粗浅的回答了。

Q：为何多线程程序会出现内存可见性问题？

A: 多线程程序未正确同步，而 Java 源代码到最终实际执行的指令序列的过程中，编译器和处理器会对指令进行重排序。

Q：如何避免出现内存可见性问题？

A：使用 Java 提供的同步原语、锁等，正确同步多线程程序。

遗留的一些疑问，后续自己解疑：

- [JSR-133 是什么？为什么要提出 JSR-133 这个规范提案？](https://jcp.org/en/jsr/detail?id=133)
